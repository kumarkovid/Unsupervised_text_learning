{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.cluster import KMeansClusterer, cosine_distance\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_kmean(train_file, test_file):\n",
    "    with open(train_file) as train_data:\n",
    "        train_data = json.load(train_data)\n",
    "        df_train = pd.DataFrame(train_data)\n",
    "        df_train.columns = ['text']\n",
    "\n",
    "    with open(test_file) as te_data:    \n",
    "        test_data = json.load(te_data)    \n",
    "        df_test = pd.DataFrame(test_data)\n",
    "        df_test.columns = ['text','label']\n",
    "    tfidf_vect = TfidfVectorizer(stop_words=\"english\",min_df=5) \n",
    "    dtm= tfidf_vect.fit_transform(df_train['text'])\n",
    "\n",
    "    num_clusters=3\n",
    "    clusterer = KMeansClusterer(num_clusters, cosine_distance, repeats=20)\n",
    "    clusters = clusterer.cluster(dtm.toarray(), assign_clusters=True) \n",
    "    centroids=np.array(clusterer.means())\n",
    "\n",
    "    sorted_centroids = centroids.argsort()[:, ::-1] \n",
    "    voc_lookup= tfidf_vect.get_feature_names()\n",
    "\n",
    "    for i in range(num_clusters):\n",
    "        top_words=[voc_lookup[word_index] for word_index in sorted_centroids[i, :20]]\n",
    "        #print(\"Cluster %d:\\n %s \" % (i, \"; \".join(top_words)))\n",
    "        \n",
    "    test_dtm = tfidf_vect.transform(df_test[\"text\"])\n",
    "    predicted = [clusterer.classify(v) for v in test_dtm.toarray()]    \n",
    "    \n",
    "    k=[]\n",
    "    for i in range(len(df_test)):\n",
    "        k.append(df_test.label.values[i][0])    # k will contain the first tag from label column for each news article\n",
    "\n",
    "    confusion_df = pd.DataFrame(list(zip(k, predicted)), columns = [\"label\", \"cluster\"])\n",
    "    confusion_df[['label']] = confusion_df[['label']].astype(str)\n",
    "    crosstab=pd.crosstab( index=confusion_df.cluster, columns=confusion_df.label)\n",
    "    print(crosstab,\"\\n\")\n",
    "    \n",
    "    j=crosstab.idxmax(axis=1)\n",
    "    cluster_dict=j.to_dict()\n",
    "    for i in range(len(cluster_dict)):\n",
    "        print(\"Cluster\",i,\":\",\"Topic\",cluster_dict[i])    \n",
    "    predicted_target=[cluster_dict[i] for i in predicted]\n",
    "    target_names = [\"0\",\"1\",\"2\"]\n",
    "    print(metrics.classification_report(k, predicted_target, target_names=target_names))\n",
    "\n",
    "    \n",
    "def cluster_lda(train_file, test_file):\n",
    "    topic_assign = None\n",
    "    labels = None\n",
    "    # add your code here\n",
    "    with open(train_file) as train_data:\n",
    "        train_data = json.load(train_data)\n",
    "        df_train = pd.DataFrame(train_data)\n",
    "        df_train.columns = ['text']\n",
    "        \n",
    "    with open(test_file) as te_data:    \n",
    "        test_data = json.load(te_data)    \n",
    "        df_test = pd.DataFrame(test_data)\n",
    "        df_test.columns = ['text','label']    \n",
    "    \n",
    "    tf_vectorizer = CountVectorizer(max_df=0.80, min_df=30, stop_words='english')\n",
    "    tf = tf_vectorizer.fit_transform(df_train['text'])\n",
    "    tf_test = tf_vectorizer.transform(df_test['text'])\n",
    "    tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "\n",
    "    K = 3\n",
    "    lda = LatentDirichletAllocation(n_components=K, max_iter=25,verbose=1, evaluate_every=1, \\\n",
    "                                    learning_method='online', n_jobs=1, random_state=0).fit(tf)   \n",
    "    topic_assign = lda.transform(tf_test)\n",
    "    prob_threshold=0.25\n",
    "    topics=np.copy(topic_assign)\n",
    "    topics=np.where(topics>=prob_threshold, 1, 0)\n",
    "    predicted_lda=topics.argmax(axis=1)\n",
    "\n",
    "    labels=[]\n",
    "    for i in range(len(df_test)):\n",
    "        labels.append(df_test.label.values[i][0])\n",
    "\n",
    "    confusion_lda_df = pd.DataFrame(list(zip(labels, predicted_lda)), columns = [\"label\", \"cluster\"])\n",
    "    confusion_lda_df[['label']] = confusion_lda_df[['label']].astype(str)\n",
    "    crosstab_lda=pd.crosstab( index=confusion_lda_df.cluster, columns=confusion_lda_df.label)\n",
    "    print(crosstab_lda)\n",
    "    \n",
    "    a = crosstab_lda.idxmax(axis=1)\n",
    "    cluster_lda_dict = a.to_dict()            # Dynamic allocation of majority vote \n",
    "    for i in range(len(cluster_lda_dict)):\n",
    "        print(\"Cluster\",i,\":\",\"Topic\",cluster_lda_dict[i])\n",
    "        \n",
    "    predicted_target_lda = [cluster_lda_dict[i] for i in predicted_lda]\n",
    "    target_names = [\"0\",\"1\",\"2\"]\n",
    "    print(metrics.classification_report(labels, predicted_target_lda,target_names=target_names))\n",
    "    return topic_assign, labels    \n",
    "\n",
    "\n",
    "def overlapping_cluster(topic_assign, labels):\n",
    "    final_thresh, f1 = None, None\n",
    "    threshold=np.arange(0.05,1.00,0.05)\n",
    "    fscore_q3=[]\n",
    "    for i in range(len(threshold)):\n",
    "        topics_q3=np.copy(topic_assign)   # from Q 2\n",
    "        topic_q3 = np.where(topics_q3>=threshold[i], 1, 0)\n",
    "        predicted_lda_q3 = topic_q3.argmax(axis=1)\n",
    "        confusion_lda_df_q3 = pd.DataFrame(list(zip(labels, predicted_lda_q3)), columns = [\"label\", \"cluster\"])\n",
    "        confusion_lda_df_q3[['label']] = confusion_lda_df_q3[['label']].astype(str)\n",
    "        crosstab_lda_q3=pd.crosstab( index=confusion_lda_df_q3.cluster, columns=confusion_lda_df_q3.label)\n",
    "\n",
    "        b = crosstab_lda_q3.idxmax(axis=1)\n",
    "        cluster_lda_dict_q3 = b.to_dict()            # Dynamic allocation of majority vote \n",
    "\n",
    "        predicted_target_lda_q3 = [cluster_lda_dict_q3[i] for i in predicted_lda_q3]\n",
    "        precision, recall, fscore, support = precision_recall_fscore_support(labels, predicted_target_lda_q3,)\n",
    "        fscore_q3.append(fscore)\n",
    "\n",
    "    fscore_data= pd.DataFrame(list(map(np.ravel, fscore_q3)))\n",
    "    fscore_data.columns=['Disaster and Accident','News and Economy','Travel & Transportation'] \n",
    "    fscore_data['Threshold'] = threshold\n",
    "    fscore_data.set_index('Threshold', inplace=True)\n",
    "\n",
    "    final_thresh = fscore_data.idxmax(axis=0)\n",
    "    f1 = fscore_data.max()\n",
    "    return final_thresh, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label    Disaster and Accident  News and Economy  Travel & Transportation\n",
      "cluster                                                                  \n",
      "0                          114                 2                      125\n",
      "1                           93                11                       36\n",
      "2                            3               193                       23 \n",
      "\n",
      "Cluster 0 : Topic Travel & Transportation\n",
      "Cluster 1 : Topic Disaster and Accident\n",
      "Cluster 2 : Topic News and Economy\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.44      0.53       210\n",
      "          1       0.88      0.94      0.91       206\n",
      "          2       0.52      0.68      0.59       184\n",
      "\n",
      "avg / total       0.69      0.69      0.68       600\n",
      "\n",
      "iteration: 1 of max_iter: 25, perplexity: 1906.9540\n",
      "iteration: 2 of max_iter: 25, perplexity: 1874.3130\n",
      "iteration: 3 of max_iter: 25, perplexity: 1861.5840\n",
      "iteration: 4 of max_iter: 25, perplexity: 1854.4301\n",
      "iteration: 5 of max_iter: 25, perplexity: 1849.5982\n",
      "iteration: 6 of max_iter: 25, perplexity: 1845.9126\n",
      "iteration: 7 of max_iter: 25, perplexity: 1842.7573\n",
      "iteration: 8 of max_iter: 25, perplexity: 1839.7916\n",
      "iteration: 9 of max_iter: 25, perplexity: 1836.9623\n",
      "iteration: 10 of max_iter: 25, perplexity: 1834.2368\n",
      "iteration: 11 of max_iter: 25, perplexity: 1831.7774\n",
      "iteration: 12 of max_iter: 25, perplexity: 1829.5951\n",
      "iteration: 13 of max_iter: 25, perplexity: 1827.5533\n",
      "iteration: 14 of max_iter: 25, perplexity: 1825.7642\n",
      "iteration: 15 of max_iter: 25, perplexity: 1824.1970\n",
      "iteration: 16 of max_iter: 25, perplexity: 1822.8113\n",
      "iteration: 17 of max_iter: 25, perplexity: 1821.5696\n",
      "iteration: 18 of max_iter: 25, perplexity: 1820.4401\n",
      "iteration: 19 of max_iter: 25, perplexity: 1819.3927\n",
      "iteration: 20 of max_iter: 25, perplexity: 1818.4056\n",
      "iteration: 21 of max_iter: 25, perplexity: 1817.4620\n",
      "iteration: 22 of max_iter: 25, perplexity: 1816.5626\n",
      "iteration: 23 of max_iter: 25, perplexity: 1815.7209\n",
      "iteration: 24 of max_iter: 25, perplexity: 1814.9489\n",
      "iteration: 25 of max_iter: 25, perplexity: 1814.2494\n",
      "label    Disaster and Accident  News and Economy  Travel & Transportation\n",
      "cluster                                                                  \n",
      "0                           44                30                      137\n",
      "1                          163                15                       43\n",
      "2                            3               161                        4\n",
      "Cluster 0 : Topic Travel & Transportation\n",
      "Cluster 1 : Topic Disaster and Accident\n",
      "Cluster 2 : Topic News and Economy\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.78      0.76       210\n",
      "          1       0.96      0.78      0.86       206\n",
      "          2       0.65      0.74      0.69       184\n",
      "\n",
      "avg / total       0.79      0.77      0.77       600\n",
      "\n",
      "Disaster and Accident      0.4\n",
      "News and Economy           0.5\n",
      "Travel & Transportation    0.2\n",
      "dtype: float64 \n",
      "\n",
      "Disaster and Accident      0.786177\n",
      "News and Economy           0.893204\n",
      "Travel & Transportation    0.720000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Due to randomness, you won't get the exact result\n",
    "# as shown here, but your result should be close\n",
    "# if you tune the parameters carefully\n",
    "# Q1\n",
    "    cluster_kmean('C:/Users/HP/Downloads/train_text.json', 'C:/Users/HP/Downloads/test_text.json')\n",
    "# Q2\n",
    "    topic_assign, labels =cluster_lda('C:/Users/HP/Downloads/train_text.json', 'C:/Users/HP/Downloads/test_text.json')\n",
    "    #cluster_lda('C:/Users/HP/Downloads/train_text.json', 'C:/Users/HP/Downloads/test_text.json')\n",
    "# Q2\n",
    "    threshold, f1 = overlapping_cluster(topic_assign, labels)\n",
    "    print(threshold,\"\\n\")\n",
    "    print(f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
